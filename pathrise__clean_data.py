# -*- coding: utf-8 -*-
"""pathrise _clean data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sZwen9kjzUKqO6dZ_M12IqmGsP3wZkJg

# Hi there, my name is Maryam. I would be delighted if you could review my code and provide your feedback.

![pathrise.svg](data:image/svg+xml;base64,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)
Data Challenge Assignment
Pathrise is an online program that provides 1-on-1 mentorship, training, and advice to help job seekers get the best possible jobs in tech. Every two weeks, Pathrise welcomes a new cohort of fellows. If a candidate is interested in joining our program and successfully passes all stages of our admission process, they receive an offer to join Pathrise and become a fellow.

On average, for fellows who stay with us after their free trial period, it takes about 4 months to receive a final job offer. However, there is a lot of variation in fellows **bold text**â€™ outcomes. Being able to predict how fast every single fellow is going to find a job is crucial for our business. In this exercise we provide you with a sample of information we collected from our fellows from the moment they joined our program.

The main goal of your analysis is to derive insights around if a fellow will ultimately be placed at a company and how long until a placement can be expected.

Objectives

Perform exploratory Data Analysis and Feature Engineering using Pandas and Matplotlib

Exploratory Data Analysis
Preparing Data Feature Engineering
"""

# pandas is a software library written for the Python programming language for data manipulation and analysis.
#Provides functionalities like reading and writing various data formats (csv, excel, etc.), managing tabular data, performing statistical calculations, and operations on data.
#Offers similarities to spreadsheet software like Excel but with more flexibility and power for complex computations.
import pandas as pd
#NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays
import numpy as np
# Matplotlib is a plotting library for python and pyplot gives us a MatLab like plotting framework. We will use this in our plotter function to plot data.
import matplotlib.pyplot as plt
#Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics
import seaborn as sns

"""# Exploratory Data Analysis (EDA)
Exploratory Data Analysis (EDA) is a crucial initial step in any data analysis project. It's like detective work for your data, where you explore, uncover patterns, and gain insights before diving into more complex modeling techniques.

First, let's read the Pathrise dataset into a Pandas dataframe and print its summar
Why Convert XLSX to CSV?
Compatibility

*   Compatibility
*   Simplicity
*   Data Sharing
---------------------------------------------------------------------
Conversion Methods:


1.   Software Programs: Several software programs can convert XLSX files to CSV, such as Microsoft Excel itself (through the "Save As" option), Google Sheets (by exporting the spreadsheet as a CSV file), or dedicated data conversion tools.
2.   Programming Languages: Programming languages like Python with libraries such as pandas (using pd.read_excel and df.to_csv) or R with libraries like readxl can be used to read XLSX files and save them as CSV files.
3. Online Converters: Online converters are also available that allow you to upload your XLSX file and download the converted CSV file. However, be cautious with online converters when dealing with sensitive data.
"""

#This line imports the files module from the google.colab library.
#This module provides functionalities specifically designed for working with files in Google Colab.
#You'll need to have a stable internet connection to upload files to Google Colab.
from google.colab import files

#This line uses the upload() function from the imported files module.
#The upload() function prompts you to upload a file from your local machine.
#Once you select the file and upload it, the function returns a dictionary-like object containing information about the uploaded file(s). In this case, the uploaded file will be stored in a variable named uploaded.
uploaded = files.upload()

#This line assumes you have a CSV file named "Data_Pathrise.csv" uploaded and stored in the uploaded variable from the previous step.
#It uses the pandas library (assuming you've imported it elsewhere in your code, typically with import pandas as pd).
#The pd.read_csv('Data_Pathrise.csv') part reads the data from the uploaded CSV file (assuming it's named "Data_Pathrise.csv") and creates a Pandas DataFrame object named df.
#A Pandas DataFrame is a powerful data structure for storing and manipulating tabular data.
df = pd.read_csv('Data_Pathrise.csv')

"""OR

"""

#mport os: This line imports the os module in Python. The os module provides functionalities for interacting with the operating system. It offers various functions for working with files, directories, processes, and more.
import os

#os.getcwd(): This line uses the getcwd() function from the imported os module. The getcwd() function stands for "get current working directory." It retrieves the absolute path of the current directory where your Python script is being executed.
os.getcwd()

#The code df= pd.read_excel('Data_Pathrise.xlsx', engine='openpyxl') reads data from an Excel spreadsheet into a Pandas DataFrame in Python.
#read_excel: This is a function within the pandas library specifically designed to read data from Excel files.
#engine='openpyxl': This is an optional argument that specifies the engine used to read the Excel file. By default, pandas uses the xlrd engine, which can handle older XLSX file formats. However, for newer XLSX formats or if you encounter issues with xlrd, you can specify engine='openpyxl' to use the openpyxl library. openpyxl is a more capable engine that supports a wider range of Excel features.
df= pd.read_excel('Data_Pathrise.xlsx', engine='openpyxl')

"""Let's go....."""

df.head()

"""# To remove the space inside the quotation"""

#The code df.columns = df.columns.str.rstrip() modifies the column names of a Pandas DataFrame.
#.str is a special accessor in Pandas that enables string operations on each element of a Series or Index (which includes column names).
#rstrip() is a string method in Python that removes any trailing whitespace from a string.
df.columns= df.columns.str.rstrip()

"""# number_of_interviews VS program_duration_days variables would affect the Placed.
The variables number_of_interviews and program_duration_days are likely to affect the Placed variable in the Pathrise dataset.
Number of Interviews:

Positive Correlation: Generally, there might be a positive correlation between the number of interviews a candidate goes through and their likelihood of getting placed. More interviews could indicate:

Stronger candidacy: A higher number of interviews suggests the candidate passed initial screenings and impressed multiple employers.
In-demand skills: If a candidate has many interviews, it might reflect their skills are highly sought-after, increasing their placement chances.
Negative Correlation (Possible): In some cases, an exceptionally high number of interviews could have a negative impact:

Extended job search: A very long interview process might suggest the candidate is struggling to find the right fit, potentially delaying placement.
Program Duration Days:

Positive Correlation (Early Stages): In the initial stages of a program, a longer program duration (more days) might provide candidates with:

Enhanced skills training: More program days could translate to more time for developing relevant skills, increasing their competitiveness.
Broader network building: Longer programs might offer more opportunities to connect with potential employers, improving placement chances.
Negative Correlation (Later Stages): As program duration extends:

Market changes: The job market can shift quickly. A very long program might leave graduates with outdated skills compared to shorter programs.
Opportunity cost: Longer programs might delay entry into the workforce, impacting earning potential.
Overall Impact:

The combined effect of these variables on Placed is likely complex and depends on the specific context. Here are some additional considerations:

Industry: The relationship between interview numbers, program duration, and placement might differ between industries.
Job Type: The impact might vary depending on the specific job role (entry-level vs. senior).
Candidate Experience: Highly experienced candidates might land placements with fewer interviews.
"""

sns.catplot(x='number_of_interviews', y='program_duration_days', hue='placed', data=df, aspect=5)
plt.xlabel("Number Interviews",fontsize=20)
plt.ylabel("Program days",fontsize=20)
plt.show()

"""# Number of highest_level_of_education"""

sns.countplot(y= 'highest_level_of_education', data=df,  orient='v')
plt.show()

df['highest_level_of_education'].value_counts()

"""# Number of professional_experience
It seems logical that people who have little experience should participate in our programs, people with experience do not need this program.
Your assumption that only people with little experience benefit from programs like yours is partially true, but there are several reasons why experienced professionals might also find value in such programs:
1. Skill Development and Updates
2. Career Transition and Advancement
3. Networking Opportunities
4. Refreshing Fundamentals
5. Confidence Boost
-----------------------------------------------
Imagine a professional with 5 years of experience. They might have a strong foundation in certain technologies, but there might be newer frameworks or tools they haven't had a chance to learn yet. Your program could bridge that gap and make them a more well-rounded candidate.

In conclusion, while targeting people with little experience can be a good strategy, don't exclude those with experience. Consider how your program can cater to their specific needs and how their experience can benefit both them and your program as a whole.

"""

sns.countplot(y= 'professional_experience', data=df,  orient='v')
plt.show()

df['professional_experience'].value_counts()

"""# Number of pathrise_status
I'll remove this column because the placed feature is marked with 1 and the active feature in the placed column is marked with 0, the rest indicate exiting the program.
Recommendation:
Instead of removing the pathrise_status column, consider recoding the values or creating dummy variables. This will preserve the original data and allow you to analyze the program's performance in more detail, including placement rate, engagement, and potential reasons for exiting the program.
"""

sns.countplot(y= 'pathrise_status', data=df,  orient='h')
plt.show()

df['pathrise_status'].value_counts()

"""I believe that this column has no effect on being placed so I'll remove it

# cohort_tag
"""

sns.countplot(x= 'cohort_tag', data=df)
plt.xticks(rotation= 90)
plt.show()

print(set(df['cohort_tag']))

df['cohort_tag'].value_counts()

"""# Number of employment_status
Analyzing the number of entries in the employment_status column, particularly for students and unemployed individuals, can be a strong indicator of why these groups might be more represented in your program.
--------------------------------------------------
Students and Unemployed People:

Available Time: Students typically have flexible schedules with significant blocks of free time, making them well-suited for intensive programs. Unemployed individuals also have more time to dedicate to the program compared to those who are already employed full-time.

Career Focus:  Students are actively preparing for their careers, and your program could be seen as a valuable stepping stone. Unemployed individuals are actively seeking new employment opportunities, and your program could equip them with the necessary skills to land a job.

Investment in Future:  Students and unemployed individuals might view the program as an investment in their future earning potential. By acquiring new skills, they increase their chances of securing a well-paying job after graduation or re-entering the workforce.

Limited Options (For Employed People):

Time Constraints: Employed individuals with full-time jobs might struggle to find the time to participate in a demanding program. Balancing work and program commitments can be challenging.

Existing Skills:  People already employed might have the skills they need for their current role. Your program might be less attractive to them unless it caters to upskilling or career transition needs.

Additional Considerations:

Program Design:  The program's structure, schedule, and time commitment might be more suitable for students and unemployed individuals. Tailoring the program to their needs could further increase their participation.

Marketing and Outreach:  Your marketing efforts might be reaching a wider audience of students and unemployed individuals compared to employed professionals.
--------------------------------------------------------------
Understanding the "Why" is Key:

While analyzing the number of entries in employment_status provides a good starting point, it's important to delve deeper to understand the motivations of different demographics. Here are some ways to gather more insights:

Surveys: Conduct surveys among program participants to understand their reasons for enrolling.
Focus Groups: Organize focus groups with students, unemployed individuals, and employed professionals to get their perspectives on the program.
Interviews: Interview program participants to gain a more detailed understanding of their experiences and motivations.

"""

sns.countplot(y= 'employment_status', data=df,  orient='v')
plt.show()

df['employment_status'].value_counts()

"""# Number of length_of_job_search"""

sns.countplot(y= 'length_of_job_search', data=df)
plt.show()

df['length_of_job_search'].value_counts()

"""# Number of Race"""

sns.countplot(y= 'race', data=df)
plt.show()

df['race'].value_counts()

"""# Number of Gender"""

sns.countplot(y= 'gender', data=df)
plt.show()

df['gender'].value_counts()

"""# Number of placed
There is an imbalance
"""

sns.countplot(x= 'placed', data=df)
plt.show()

df['placed'].value_counts()

"""# Number of length_of_job_search"""

df_count=df['length_of_job_search'].value_counts()
df_count

count=list(df_count.values)
index=list(df_count.index)

print(count)
print(index)

"""# The percentage of job_search_length by Pie Chart

"""

plt.pie(count,labels=index, autopct='%.0f%%')
plt.title('Total')
plt.show()

"""# Classification of plased and non-plased data"""

df_placed= df[df['placed']==1]
df_unplaced= df[df['placed']!=1]

"""# The percentage of job_search_length "placed" by Pie Chart"""

df_count_placed=df_placed['length_of_job_search'].value_counts()
count_placed=list(df_count_placed.values)
index_placed=list(df_count_placed.index)
plt.pie(count_placed,labels=index_placed, autopct='%.0f%%')
plt.title('placed')
plt.show()

df_count_placed

"""# Number of Gender that placed"""

sns.countplot(y= 'gender', data=df_placed)
plt.show()

"""# Number of highest_level_of_education that placed"""

df_count_placed=df_placed['highest_level_of_education'].value_counts()
count_placed=list(df_count_placed.values)
index_placed=list(df_count_placed.index)
plt.pie(count_placed,labels=index_placed, autopct='%.0f%%')
plt.title('placed')
plt.show()

"""# Number of professional_experience that placed"""

df_count_placed=df_placed['professional_experience'].value_counts()
count_placed=list(df_count_placed.values)
index_placed=list(df_count_placed.index)
plt.pie(count_placed,labels=index_placed, autopct='%.0f%%')
plt.title('placed')
plt.show()

"""# Features Engineering
By now, you should obtain some preliminary insights about how each important variable would affect the success rate, we will select the features that will be used in success prediction in the future module.
"""

df.head()

df.info()

"""# I delete the columns that do not affect the result
Why Delete Columns?

There are several reasons why you might want to remove columns from a DataFrame:

Focus on Relevant Data: If certain columns are not relevant to your analysis, removing them can make the DataFrame more manageable and easier to work with.
Reduce Redundancy: If columns contain duplicate information, keeping only one might be sufficient.
Improve Performance: For large datasets, removing unnecessary columns can improve processing speed and memory usage.
"""

#By default (axis=0), it removes rows
df= df.drop(['id', 'pathrise_status', 'cohort_tag'], axis=1)

"""# Now delete N/A on program_duration_days column

*   Dropping rows with N/A values can affect the size and statistical properties of your data. Make sure this aligns with your analysis goals.
*   Consider replacing N/A values with appropriate strategies (e.g., imputation techniques) if keeping those rows is essential for your analysis.


 Common Imputation Methods
1.   Mean Imputation
2.   Median Imputation
3.   Mode Imputation
4.   Random Sampling Imputation
5.   Predictive Modeling Imputation







"""

# Missing values:
#The program_duration_days column may contain a large number of missing values. dropna by default drops all rows that have a missing value in any of the columns specified in subset.
df= df.dropna(subset=['program_duration_days'])

df.info()

"""# Create dummy variables to categorical columns

"""

df_dummy= pd.get_dummies(df[['primary_track', 'employment_status', 'highest_level_of_education', 'length_of_job_search', 'biggest_challenge_in_search', 'professional_experience', 'work_authorization_status', 'gender', 'race']])

df_dummy.head().astype(int)

df= df.drop(['primary_track', 'employment_status', 'highest_level_of_education', 'length_of_job_search', 'biggest_challenge_in_search', 'professional_experience', 'work_authorization_status', 'gender', 'race'], axis=1)

df= pd.concat([df, df_dummy], axis=1)

df.info()

df=df.dropna(subset=['number_of_interviews'])

df.info()

"""# Cast all numeric columns to float64
Now that our df dataframe only contains numbers cast the entire dataframe to variable type float64.

There are several reasons why you might want to convert DataFrame columns to float64. Some of the most common reasons include:

1. Compatibility:
float64 is the standard data type for decimal numbers in Python.
Using float64 for numeric DataFrame columns can help ensure that your code is compatible with other Python libraries and functions that expect to receive data as float64.

2. Precision:
float64 is a high-precision data type that can store decimal numbers with a high degree of accuracy.
If you are working with decimal numbers in your DataFrame, converting them to float64 can help to preserve the accuracy of your calculations.

3. Performance:
Some mathematical and statistical operations in Python may be faster with float64 data than with other data types such as int.
If you need to perform a lot of computations on your DataFrame, converting the numeric columns to float64 may improve the performance of your code.

4. Analysis:
Many popular data analysis libraries and visualization tools are designed to work with float64 data.
Converting the columns in your DataFrame to float64 can make it easier to analyze and visualize your data.
"""

df= df.astype(float)

df.info()

"""# We can now export it to a CSV for the next section
In simpler terms, this code is saving the processed data stored in your DataFrame (df) as a CSV file named 'Pathrise_processedData.csv' on your computer. CSV files are a common way to store and share data in a format that can be easily opened by many different software programs
"""

df.to_csv('Pathrise_processedData.csv')